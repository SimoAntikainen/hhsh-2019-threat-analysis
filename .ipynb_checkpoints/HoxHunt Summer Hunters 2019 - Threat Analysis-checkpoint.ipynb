{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoxHunt Summer Hunters 2019 - Data - Home assignment\n",
    "\n",
    "\n",
    "## What we expect\n",
    "\n",
    "Investigate potential features you could extract from the given URL and implement extractors for the ones that interest you the most. Below example code extracts one feature but does not store it very efficiently (just console logs it). Implement sensible data structure using some known data structure library to store the features per URL. Also consider how would you approach error handling if one feature extractor fails?\n",
    "\n",
    "Be prepared to discuss questions such as: what features could indicate the malicousness of a given URL? What goes in to the thinking of the attacker when they are choosing a site for an attack? What would you develop next?\n",
    "\n",
    "## What we don't expect\n",
    "\n",
    "Implement a humangous set of features.\n",
    "\n",
    "Implement any kind of actual predicition models that uses the features to give predictions on malicousness at this stage :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import urlopen\n",
    "import tldextract\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#import whois (also you need to install whois tool on system seperately) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the study [1] which built a phishing website classifier using five types of features sets (f1-5) we can see that url related features (f1) had the best precision, recall and FP-rate when classifiying phishing sites, but a combination of url and webpage content related features (f5) provided performance close to the classifier containing all the features when it comes to recall and FP-rate. This succest that combining these feature sets might be a good starting point when building a classfier. However, it can be noted that the research did not record the performance of any other pair of two features other than the pair f1,5.\n",
    "\n",
    "I also looked at the twitter phishing paper [2], which used WHOIS information of registrar name and domain age to identify phishing sites. Will need scrape these features from some online WHOIS site as the internal tool does not work good enough.\n",
    " \n",
    "[1] [Know Your Phish: Novel Techniques for Detecting\n",
    "Phishing Sites and their Targets](https://arxiv.org/pdf/1510.06501.pdf)\n",
    "\n",
    "[2] [PhishAri: Automatic Realtime Phishing Detection on Twitter](https://arxiv.org/pdf/1301.6899.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL-related features\n",
    "\n",
    "From the url related features f1 in [1] we build extractors for 8 of the 9 url related features for starting and landing url.  \n",
    "\n",
    "1 protocol used (http/https)<br>\n",
    "2 count of dots ‘.’ in FreeURL<br>\n",
    "3 count of level domains<br>\n",
    "4 length of the URL<br>\n",
    "5 length of the FQDN<br>\n",
    "6 length of the mld<br>\n",
    "7 count of terms in the URL<br>\n",
    "8 count of terms in the mld<br>\n",
    "\n",
    "Intuitively these form a good starting point for the classifier as I can often see from the pure url if the site is trustful with the exception if the site is between an url shortener. \n",
    "\n",
    "There are also a large number of url features related to links inside the landing page, which are important for the classfier to work correctly and which I should build next to replicate the performance of f1 feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_urls = [\"https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus\",\n",
    "                \"http://cartaobndes.gov.br.cv31792.tmweb.ru/\",\n",
    "                \"https://paypal.co.uk.yatn.eu/m/\",\n",
    "                \"http://college-eisk.ru/cli/\",\n",
    "                \"https://dotpay-platnosc3.eu/dotpay/\"\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus',\n",
       "  'https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus'),\n",
       " ('http://cartaobndes.gov.br.cv31792.tmweb.ru/',\n",
       "  'https://vh76.timeweb.ru/parking/?ref=cartaobndes.gov.br.cv31792.tmweb.ru'),\n",
       " ('https://paypal.co.uk.yatn.eu/m/', None),\n",
       " ('http://college-eisk.ru/cli/', None),\n",
       " ('https://dotpay-platnosc3.eu/dotpay/', None)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_land_urls = []\n",
    "for url in example_urls:\n",
    "    try:\n",
    "        response = urlopen(url)\n",
    "        landing_url = response.geturl()\n",
    "        start_land_urls.append((url, landing_url))\n",
    "    except:\n",
    "        start_land_urls.append((url, None))\n",
    "\n",
    "start_land_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https', 'www.amazon.co.uk', 'amazon.co.uk', 'amazon', 'www', '/ap/signin')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parses the url to components described in [1]. \n",
    "def url_components(url):\n",
    "    url_parsed =  urlparse(url)\n",
    "    url_extracted = tldextract.extract(url)\n",
    "    \n",
    "    protocol = url_parsed.scheme\n",
    "    FQDN = url_parsed.netloc\n",
    "    RDN = url_extracted.domain + '.' + url_extracted.suffix\n",
    "    mld = url_extracted.domain\n",
    "    FreeURL_start = url_extracted.subdomain\n",
    "    FreeURL_end = url_parsed.path\n",
    "    \n",
    "    return (protocol,FQDN, RDN,mld,FreeURL_start, FreeURL_end)\n",
    "\n",
    "url_components('https://www.amazon.co.uk/ap/signin? encoding=UTF8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_features(url):\n",
    "    \n",
    "    if url != None:\n",
    "         \n",
    "        protocol,FQDN, RDN, mld, FreeURL_start, FreeURL_end = url_components(url)\n",
    "        \n",
    "        protocol_used = 1 if protocol == 'https' else 0\n",
    "        free_url_dots = FreeURL_start.count('.') +  FreeURL_end.count('.')\n",
    "        \n",
    "        #Count of level domains, this is not accuarate as subdomains get added if they exist.\n",
    "        level_domain = FQDN.count('.')\n",
    "\n",
    "        url_length = len(url)\n",
    "        FQDN_length = len(FQDN)\n",
    "        mld_length = len(mld)\n",
    "         \n",
    "        url_terms = len(re.split(r\"[/:\\.?=&-_]+\",url))\n",
    "        mld_terms = len(re.split(r\"[-]+\",mld))\n",
    " \n",
    "        return [protocol_used,free_url_dots,level_domain,  url_length,FQDN_length,mld_length,url_terms,mld_terms]\n",
    "    else:\n",
    "        return [None] * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting-url</th>\n",
       "      <th>protocol</th>\n",
       "      <th>free-url-dots</th>\n",
       "      <th>level_domain</th>\n",
       "      <th>url-len</th>\n",
       "      <th>fqdn-len</th>\n",
       "      <th>mld-len</th>\n",
       "      <th>url-terms</th>\n",
       "      <th>mld-terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.slideshare.net/weaveworks/client-s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://cartaobndes.gov.br.cv31792.tmweb.ru/</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://paypal.co.uk.yatn.eu/m/</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://college-eisk.ru/cli/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dotpay-platnosc3.eu/dotpay/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        starting-url protocol free-url-dots  \\\n",
       "0  https://www.slideshare.net/weaveworks/client-s...        1             0   \n",
       "1        http://cartaobndes.gov.br.cv31792.tmweb.ru/        0             3   \n",
       "2                    https://paypal.co.uk.yatn.eu/m/        1             2   \n",
       "3                        http://college-eisk.ru/cli/        0             0   \n",
       "4                https://dotpay-platnosc3.eu/dotpay/        1             0   \n",
       "\n",
       "  level_domain url-len fqdn-len mld-len url-terms mld-terms  \n",
       "0            2      76       18      10        10         1  \n",
       "1            5      43       35       5         8         1  \n",
       "2            4      31       20       4         8         1  \n",
       "3            1      27       15      12         6         2  \n",
       "4            1      35       19      16         6         2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names =  ['starting-url', 'protocol', 'free-url-dots','level_domain',\n",
    "              'url-len', 'fqdn-len', 'mld-len','url-terms','mld-terms']\n",
    "\n",
    "df_start  = pd.DataFrame(columns = col_names)\n",
    "for url in start_land_urls:\n",
    "    df_start.loc[len(df_start)] = [url[0]] + url_features(url[0])\n",
    "df_start.head()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landing-url</th>\n",
       "      <th>protocol</th>\n",
       "      <th>free-url-dots</th>\n",
       "      <th>level_domain</th>\n",
       "      <th>url-len</th>\n",
       "      <th>fqdn-len</th>\n",
       "      <th>mld-len</th>\n",
       "      <th>url-terms</th>\n",
       "      <th>mld-terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.slideshare.net/weaveworks/client-s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vh76.timeweb.ru/parking/?ref=cartaobnd...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         landing-url protocol free-url-dots  \\\n",
       "0  https://www.slideshare.net/weaveworks/client-s...        1             0   \n",
       "1  https://vh76.timeweb.ru/parking/?ref=cartaobnd...        1             0   \n",
       "2                                               None     None          None   \n",
       "3                                               None     None          None   \n",
       "4                                               None     None          None   \n",
       "\n",
       "  level_domain url-len fqdn-len mld-len url-terms mld-terms  \n",
       "0            2      76       18      10        10         1  \n",
       "1            2      72       15       7        12         1  \n",
       "2         None    None     None    None      None      None  \n",
       "3         None    None     None    None      None      None  \n",
       "4         None    None     None    None      None      None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names =  ['landing-url', 'protocol', 'free-url-dots','level_domain',\n",
    "              'url-len', 'fqdn-len', 'mld-len','url-terms','mld-terms']\n",
    "\n",
    "df_land  = pd.DataFrame(columns = col_names)\n",
    "for url in start_land_urls:\n",
    "    df_land.loc[len(df_land)] = [url[1]] + url_features(url[1])\n",
    "df_land.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webpage content features\n",
    "\n",
    "From [1] we consider the full set of f5 webpage content features: the number of terms in title and body, the number of input fiels, images and iframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text\n",
    "def tag_visible(element):  \n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def text_from_html(soup): \n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    \n",
    "    return u\" \".join(t.strip() for t in visible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_terms_amount(soup):\n",
    "    title = soup.find('title').string\n",
    "    tokenized_title = word_tokenize(title)\n",
    "    long_terms = [x for x in tokenized_title if len(x) >= 3]\n",
    "    \n",
    "    return len(set(long_terms))\n",
    "\n",
    "def body_terms_amount(soup):  \n",
    "    text = text_from_html(soup)\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    long_terms = [x for x in tokenized_text if len(x) >= 3]\n",
    "    \n",
    "    return len(set(long_terms))\n",
    "\n",
    "def input_field_amount(soup):\n",
    "    #the research paper does not discern between types of input fields\n",
    "    input_fields = soup.find_all('input')\n",
    "    \n",
    "    return len(input_fields)\n",
    "\n",
    "def images_amount(soup):\n",
    "    images = soup.find_all('img')\n",
    "    \n",
    "    return len(images)\n",
    "\n",
    "def iframes_amount(soup):\n",
    "    iframes = soup.find_all('iframe')\n",
    "    \n",
    "    return len(iframes)\n",
    "\n",
    "def content_features(url): \n",
    "    if url != None:\n",
    "        \n",
    "        try:\n",
    "            page = urlopen(url).read()\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "            title_terms_count = title_terms_amount(soup)      \n",
    "            body_terms_count = body_terms_amount(soup)\n",
    "            inputs_count = input_field_amount(soup)\n",
    "            images_count = images_amount(soup)\n",
    "            iframes_count = iframes_amount(soup)    \n",
    "      \n",
    "            return [title_terms_count, body_terms_count, inputs_count, images_count, iframes_count]\n",
    "        except:\n",
    "            return [None] * 5\n",
    "    else:\n",
    "        return [None] * 5\n",
    "    \n",
    "#print(content_features(example_urls[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landing-url</th>\n",
       "      <th>title-terms</th>\n",
       "      <th>body-terms</th>\n",
       "      <th>inputs-count</th>\n",
       "      <th>images-count</th>\n",
       "      <th>iframes-count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.slideshare.net/weaveworks/client-s...</td>\n",
       "      <td>5</td>\n",
       "      <td>413</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vh76.timeweb.ru/parking/?ref=cartaobnd...</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         landing-url title-terms body-terms  \\\n",
       "0  https://www.slideshare.net/weaveworks/client-s...           5        413   \n",
       "1  https://vh76.timeweb.ru/parking/?ref=cartaobnd...           5         65   \n",
       "2                                               None        None       None   \n",
       "3                                               None        None       None   \n",
       "4                                               None        None       None   \n",
       "\n",
       "  inputs-count images-count iframes-count  \n",
       "0           13           50             1  \n",
       "1            0            1             1  \n",
       "2         None         None          None  \n",
       "3         None         None          None  \n",
       "4         None         None          None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names =  ['landing-url', 'title-terms', 'body-terms', 'inputs-count', 'images-count', 'iframes-count']\n",
    "df_content  = pd.DataFrame(columns = col_names)\n",
    "for url in start_land_urls:\n",
    "    df_content.loc[len(df_content)] = [url[1]] + content_features(url[1])\n",
    "df_content.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "### links\n",
    "[Know Your Phish: Novel Techniques for Detecting\n",
    "Phishing Sites and their Targets](https://arxiv.org/pdf/1510.06501.pdf)\n",
    "\n",
    "[DeltaPhish: Detecting Phishing Webpages\n",
    "in Compromised Websites](https://arxiv.org/pdf/1707.00317.pdf)\n",
    "\n",
    "\n",
    "\n",
    "[PhishAri: Automatic Realtime Phishing Detection on Twitter](https://arxiv.org/pdf/1301.6899.pdf)\n",
    "\n",
    "\n",
    "\n",
    "[More or Less? Predict the Social Influence of Malicious URLs on Social Media\n",
    "](https://arxiv.org/abs/1812.02978)\n",
    "\n",
    "\n",
    "\n",
    "[awesome-threat-intelligence](https://github.com/hslatman/awesome-threat-intelligence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slideshare.net\n",
      "https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus 4741\n",
      "tmweb.ru\n",
      "http://cartaobndes.gov.br.cv31792.tmweb.ru/ 4655\n",
      "yatn.eu\n",
      "https://paypal.co.uk.yatn.eu/m/ None\n",
      "college-eisk.ru\n",
      "http://college-eisk.ru/cli/ 2723\n",
      "dotpay-platnosc3.eu\n",
      "https://dotpay-platnosc3.eu/dotpay/ None\n"
     ]
    }
   ],
   "source": [
    "def get_domain_age_in_days(domain):\n",
    "    print(domain)\n",
    "    show = \"https://input.payapi.io/v1/api/fraud/domain/age/\" + domain\n",
    "    data = requests.get(show).json()\n",
    "    return data['result'] if 'result' in data else None\n",
    "\n",
    "def parse_domain_from_url(url):\n",
    "    t = urlparse(url).netloc\n",
    "    return '.'.join(t.split('.')[-2:])\n",
    "\n",
    "def analyze_url(url):\n",
    "    # First feature, if domain is new it could indicate that the bad guy has bought it recently...\n",
    "    age_in_days_feature = get_domain_age_in_days(parse_domain_from_url(url));\n",
    "    # Hmm...maybe I could do something more sensible with the data than just printing out\n",
    "    print(url, age_in_days_feature)\n",
    "\n",
    "# Note some of these urls are live phishing sites (as of 2019-03-21) use with caution! More can be found at https://www.phishtank.com/\n",
    "example_urls = [\"https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus\",\n",
    "                \"http://cartaobndes.gov.br.cv31792.tmweb.ru/\",\n",
    "                \"https://paypal.co.uk.yatn.eu/m/\",\n",
    "                \"http://college-eisk.ru/cli/\",\n",
    "                \"https://dotpay-platnosc3.eu/dotpay/\"\n",
    "               ]\n",
    "for url in example_urls: \n",
    "    analyze_url(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might add WHOIS features in the future, if I get the whois to work more reliably\n",
    "url_parsed =  urlparse('https://en.wikipedia.org/wiki/Domain_name_registrar')\n",
    "FQDN = url_parsed.netloc\n",
    "print(FQDN)\n",
    "\n",
    "domain = whois.query(FQDN)\n",
    "#domain.registrar\n",
    "#domain.creation_date\n",
    "print(domain.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
